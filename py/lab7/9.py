import re
def telugu_tokenizer(text):
    patterns = {
        "punctuation": r"[.,!?;:\"'()üë¶üë¶{}]",
        "date": r"\b(?:\d{1,2}[-/]\d{1,2}[-/]\d{2,4}|\d{1,2} [A-Za-z]+ \d{2,4})\b",
        "url": r"https?://[^\s]+",
        "email": r"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}",
        "number": r"\b(?:\d{1,3}(?:,\d{2,3})*|\d+\.\d+|\d+/\d+|\d+)\b", 
        "telugu_number": r"[\u0C66-\u0C6F]+(?:[.,][\u0C66-\u0C6F]+)?",
        "social_media": r"[@#][\w]+",
        "telugu_word": r"[\u0C00-\u0C7F]+", 
    }
    combined_pattern = "|".join(f"(?P<{key}>{pattern})" for key, pattern in patterns.items())

    tokens = []
    
    for match in re.finditer(combined_pattern, text):
        for key, value in match.groupdict().items():
            if value:
                tokens.append((key, value))

    return tokens
text = """
‡∞®‡∞æ ‡∞™‡±á‡∞∞‡±Å ‡∞µ‡∞Ç‡∞∂‡±Ä. ‡∞®‡∞æ ‡∞á‡∞Æ‡±Ü‡∞Ø‡∞ø‡∞≤‡±ç test@example.com. ‡∞®‡∞æ ‡∞∏‡±à‡∞ü‡±ç https://example.com.  
‡∞®‡∞æ ‡∞´‡±ã‡∞®‡±ç 98456-78901. ‡∞®‡∞æ ‡∞ü‡±ç‡∞µ‡∞ø‡∞ü‡±ç‡∞ü‡∞∞‡±ç @vamsi_123. ‡∞®‡∞ø‡∞®‡±ç‡∞® ‡∞®‡±á‡∞®‡±Å 10-03-2025‡∞® ‡∞µ‡±Ü‡∞≥‡±ç‡∞≤‡∞æ‡∞®‡±Å.  
‡∞¶‡∞ø‡∞ó‡±Å‡∞µ ‡∞∏‡∞Ç‡∞ñ‡±ç‡∞Ø ‡±©‡±©.‡±ß‡±´ ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å 3,22,243. 
"""

tokens = telugu_tokenizer(text)
for token_type, token_value in tokens:
    print(f"{token_type}: {token_value}")